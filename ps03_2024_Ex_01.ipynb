{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Install NLTK Library\n",
        "\n"
      ],
      "metadata": {
        "id": "8MIM8x5xbgla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyBWkFW6azW_",
        "outputId": "c5b24546-7e9d-45c6-dce3-9c3a5e1260ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "#install nltk library\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the word_tokenize function from nltk.tokenize."
      ],
      "metadata": {
        "id": "KAOiHaGwcDWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist"
      ],
      "metadata": {
        "id": "2HgdT6KYboHg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download nltk package\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4auVqv1Uda7H",
        "outputId": "eade2b7b-035c-46ef-eb7b-ebd2ba7f3cb3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a variable ‘text’ that contains a paragraph of at least 4 sentences about any topic of your choice."
      ],
      "metadata": {
        "id": "9ElsnWYjcS1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Conversational AI Subject is really helping me to learn new AI tools. This subject provides a lot of instances to future tech tools. Conversation AI subject is Important to me. I really like Artificial Intelligence Course.\""
      ],
      "metadata": {
        "id": "dAsN0AuccL1x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use the word_tokenize function to tokenize the text into words."
      ],
      "metadata": {
        "id": "Yw-01oKhcTI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using word_tokenize to convert text to words\n",
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "0PlOZNFIdPM4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Print the list of tokens."
      ],
      "metadata": {
        "id": "BpcyU2gGcTXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"List of Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV9LFOwSccz4",
        "outputId": "ec0b067e-4263-4548-f6fc-49eea05f0805"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Tokens: ['Conversational', 'AI', 'Subject', 'is', 'really', 'helping', 'me', 'to', 'learn', 'new', 'AI', 'tools', '.', 'This', 'subject', 'provides', 'a', 'lot', 'of', 'instances', 'to', 'future', 'tech', 'tools', '.', 'Conversation', 'AI', 'subject', 'is', 'Important', 'to', 'me', '.', 'I', 'really', 'like', 'Artificial', 'Intelligence', 'Course', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Count the number of tokens in the text."
      ],
      "metadata": {
        "id": "xccLnJxrdylN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(tokens)\n",
        "print(\"Number of Tokens:\", num_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGGP42prduSX",
        "outputId": "49bc6a07-f175-48ec-9f2b-f5ff3ceeea92"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Tokens: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify the frequency of each token using nltk.FreqDist or other function."
      ],
      "metadata": {
        "id": "264lDHF1d8h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find and print the frequency distribution of token\n",
        "freq_dist = FreqDist(tokens)\n",
        "print(\"Token Frequency\")\n",
        "for word, frequency in freq_dist.items():\n",
        "    print(f\"{word}: {frequency}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GesaVPZmd6IF",
        "outputId": "008866ce-1c54-4a3c-e057-53bc4cd95b51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Frequency\n",
            "Conversational: 1\n",
            "AI: 3\n",
            "Subject: 1\n",
            "is: 2\n",
            "really: 2\n",
            "helping: 1\n",
            "me: 2\n",
            "to: 3\n",
            "learn: 1\n",
            "new: 1\n",
            "tools: 2\n",
            ".: 4\n",
            "This: 1\n",
            "subject: 2\n",
            "provides: 1\n",
            "a: 1\n",
            "lot: 1\n",
            "of: 1\n",
            "instances: 1\n",
            "future: 1\n",
            "tech: 1\n",
            "Conversation: 1\n",
            "Important: 1\n",
            "I: 1\n",
            "like: 1\n",
            "Artificial: 1\n",
            "Intelligence: 1\n",
            "Course: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vb34kpdneFD9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}